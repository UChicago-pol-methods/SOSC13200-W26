# AI Policy + Expectations

This course treats AI tools (including Claude Code) as **learning aids**, not substitutes for your own thinking. 
You may use Claude Code to help you write, run, and debug code, but you are responsible for the **design, interpretation, and verification** of every result you submit. 

---

## 1) What’s allowed

Use Claude Code to:
- **Debug** errors and interpret error messages.
- **Prototype** code and refactor for clarity.
- Generate **tests/sanity checks** (e.g., missingness checks, balance tables, placebo tests, simulation checks).
- Ask for **conceptual explanations** (e.g., “What does this estimand represent?” “What assumptions does this require?”).
- Improve **reproducibility** (project structure, `renv`, scripts, README).
- Safety **check** for linguistic errors or typos--as you would a spell check or grammar tool. 

---

## 2) What’s required

### A. Transparency: 
For every assignment/project, you must submit:
1) A short statement (2–5 lines) that includes:
   - What (if anything) you asked Claude to do (at a high level).
   - What you took on, changed, or rejected from Claude's suggestions.

### B. Verification:
Some submissions will include **Verification** sections with checks, such as:
- Reproduce the same quantity **two ways** (e.g., difference-in-means and regression).
- A **small-n** or hand-check on a subset.
- A **diagnostic plot/table** that would catch common mistakes.

If your result cannot be verified and defended, it will not receive full credit.

---

## 3) What’s not allowed

- Submitting AI-written narrative answers as your own without substantial original reasoning.
- Turning in analyses you **cannot explain** (methods, assumptions, code, interpretation).
- Hallucinated citations or results.
- Using AI during any **closed-tool** assessment (in-class discussions, exams), unless explicitly permitted.

---

## 4) Data, privacy, and responsible use

- Do not paste sensitive/private data into AI tools. 
- Keep your work in a dedicated course project folder/repo.
- You are responsible for ensuring outputs are accurate; AI can be confidently wrong.

---